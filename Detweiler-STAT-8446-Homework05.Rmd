---
title: "Homework 5"
author: "Brian Detweiler"
date: "March 2 , 2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(TSA)
```

# 1. For each of the following, identify it as an ARIMA model. That is, find the values of $p, d$, and $q$ and the values of the parameters ($\phi$'s and $\theta$'s). Recall that by definition ARMA($p, q$) models must be stationary and invertible.

## (a) $Y_t = 0.6 Y_{t - 1} + 0.4 Y_{t - 2} + e_t - 0.5 e_{t - 1} + 0.25 e_{t - 2}$

This appears to be an ARMA(2, 2), with $\phi_1 = 0.6$ and $\phi_2 = 0.4$, $\theta_1 = -0.5$ and $\theta_2 = 0.25$. 

We must verify the assumptions that it is stationary and invertible.

$$
\begin{split}
  \phi_1 + \phi_2 &= 0.6 + 0.4 = 1.0 \nless 1.0\\
  \phi_2 - \phi_1 &= 0.4 - 0.6 = -0.2 < 1 \\
  |\phi_2| &= 0.4 < 1 \\
\end{split}
$$

Here the first constraint is violated, so we transform this to the first difference, $\nabla_t = Y_t - Y_{t - 1}$ \\

$$
\begin{split}
  Y_t &= 0.6 Y_{t - 1} + 0.4 Y_{t - 2} + e_t - 0.5 e_{t - 1} + 0.25 e_{t - 2} \\
  Y_t - Y_{t - 1} &= (0.6 Y_{t - 1} + 0.4 Y_{t - 2} + e_t - 0.5 e_{t - 1} + 0.25 e_{t - 2}) - Y_{t - 1} \\
  \nabla Y_t &= 0.6 Y_{t - 1} - Y_{t - 1} + 0.4 Y_{t - 2} + e_t - 0.5 e_{t - 1} + 0.25 e_{t - 2} \\
  &= -0.4 Y_{t - 1} + 0.4 Y_{t - 2} + e_t - 0.5 e_{t - 1} + 0.25 e_{t - 2} \\
\end{split}
$$

Letting $W_t = \nabla Y_t$, we have

$$
\begin{split}
  W_t &= -0.4 W_{t - 1} + e_t - 0.5 e_{t - 1} + 0.25 e_{t - 2} \\
\end{split}
$$

Now this appears to be an ARMA(1, 2) with

$$
\begin{split}
  \phi_1 &= -0.4 \\
  \theta_1 &= -0.5 \\
  \theta_2 &= 0.25 \\
\end{split}
$$

Checking constraints, we have

$$
\begin{split}
  \phi_1 + \phi_2 &= -0.4 + 0 = -1.0 < 1 \\
  \phi_2 - \phi_1 &= 0 - (-0.4) = 0.4 < 1 \\
  |\phi_2| &= 0 < 1 \\
\end{split}
$$

Likewise, checking for invertibility, we have

$$
\begin{split}
  \theta_1 + \theta_2 &= -0.5 + 0.25 = -0.25 < 1\\
  \theta_2 - \theta_1 &= 0.25 - (-0.5) = 0.75 < 1 \\
  |\theta_2| &= 0.25 < 1 \\
\end{split}
$$

The constraints are satisfied, and thus the first difference $W_t$ is ARMA(1, 2). Therefore, $Y_t$ is ARIMA(1, 1, 2). 

## (b) $Y_t = 2 Y_{t - 1} - Y_{t - 2} + e_t$

Verifying the assumptions that it is stationary and invertible,

$$
\begin{split}
  \phi_1 + \phi_2 &= 2 + (-1) = 1.0 \nless 1.0\\
  \phi_2 - \phi_1 &= (-1) - 2 = -3 < 1 \\
  |\phi_2| &= 1 \nless 1 \\
\end{split}
$$

Since the assumptions are violated, this is not stationary as an AR(2) model.

We can actually rewrite this as $\nabla Y_t$, and we have

$$
\begin{split}
  Y_t &= Y_{t - 1} + Y_{t - 1} - Y_{t - 2} + e_t \\
  Y_t - Y_{t - 1} &=  Y_{t - 1} - Y_{t - 2} + e_t \\
  \nabla Y_{t} &=  Y_{t - 1} - Y_{t - 2} + e_t \\
\end{split}
$$

Verifying the assumptions for stationary, we have

$$
\begin{split}
  \phi_1 + \phi_2 &= 1 + (-1) = 0 < 1.0\\
  \phi_2 - \phi_1 &= 1 - (-1) = 2 \nless 1 \\
  |\phi_2| &= 1 \nless 1 \\
\end{split}
$$

So this is still not stationary.

Now we look at the second difference,

$$
\begin{split}
  \nabla^2 Y_{t} &= \nabla (\nabla Y_t) \\
  W_t &= \nabla (Y_t - Y_{t - 1}) = Y_t - 2 Y_{t - 1} + Y_{t - 2} \\
\end{split}
$$

Now, since $W_t = Y_t - 2 Y_{t - 1} + Y_{t - 2} = e_t$, the second difference is a white noise process. Thus, it is an IMA(2, 0).


## (c) $Y_t = 0.5 Y_{t - 1} - 0.5 Y_{t - 2} + e_t - 0.1 e_{t - 1}$

This seems to be an ARMA(2, 1) with $\phi_1 = 0.5, \phi_2 = -0.5$ and $\theta_1 = -0.1$.

The conditions for stationary hold,
$$
\begin{split}
  \phi_1 + \phi_2 &= 0.5 + (-0.5) = 0 < 1.0\\
  \phi_2 - \phi_1 &= -0.5 + 0.5 = 0 < 1 \\
  |\phi_2| &= 0.5 < 1 \\
\end{split}
$$

And since $|\theta_1| = 0.1 < 1$, then it is also invertible.


\begin{flushright}
  $\blacksquare$
\end{flushright}

\pagebreak


# 2. For each ARIMA model described in Question 1, find the numerical values of $\psi_0, \psi_1, \psi_2, \psi_3, \psi_4$ and a recurrence relation for $\psi_k, k > 4$.

## (a) $Y_t = 0.6 Y_{t - 1} + 0.4 Y_{t - 2} + e_t - 0.5 e_{t - 1} + 0.25 e_{t - 2}$

$$
\begin{split}
  \phi_1 &= -0.4 \\
  \theta_1 &= -0.5 \\
  \theta_2 &= 0.25 \\
\end{split}
$$

As always, $\psi_0 = 1$.

$$
\begin{split}
  \psi_1 &= 0.5 = \psi_1 - 0.6 \psi_0 = 1.1 \\
  &= 0.5 = \psi_1 - 0.6 (1) = 1.1 \\
  \psi_2 &= -0.25 = \psi_2 - 0.6 \psi_1 - 0.4 \psi_0 \\
  \psi_2 &= -0.25 = \psi_2 - 0.6 (1.1) - 0.4 (1) \\
  \psi_2 &= 0.81 \\
  \psi_3 &= 0 = \psi_3 - 0.6 \psi_2 - 0.4 \psi_1 \\
  \psi_3 &= 0 = \psi_3 - 0.6 \psi_2 - 0.4 \psi_1 \\
  &= 0.9260 \\
  \psi_4 &= 0 = \psi_4 - 0.6 \psi_3 -0.4 \psi_2 \\
  &= 0.8796 \\
  \theta_k &= \psi_k - \phi_1 \psi_{k - 1} - \phi_2 \psi_{k - 2} - \hdots - \phi_n \psi_{k - n} \\
\end{split}
$$



\begin{flushright}
  $\blacksquare$
\end{flushright}

\pagebreak

# 3. Consider a stationary process $\{Y_t\}$. Show that if $\rho_1  < 0.5$ then $\nabla Y_t$ has a larger variance than $Y_t$.

We will show that $Var(\nabla Y_t) > Var(Y_t)$.

Since $\{Y_t\}$ is stationary, $Var(Y_t) = \gamma_0 = \sigma^2$ is a constant.

We have $Var(\nabla Y_t) = Var(Y_t - Y_{t - 1})$. 

By the properties of variance and letting $k = 1$, 
$$
\begin{split}
  Var(\nabla Y_t) &= Var(Y_t) + Var(Y_{t - k}) - 2Cov(Y_t, Y_{t - k})\\
  &= \gamma_0 + \gamma_0 - 2 \gamma_{k} \\
  &= 2 \gamma_0 - 2 \gamma_{k} \\
  &= 2 (\gamma_0 - \gamma_{k}) \\
  &= 2 (\gamma_0 - \gamma_{k}) \\
\end{split}
$$

Since $\rho_1 = \frac{\gamma_k}{\gamma_0}$, we have
$$
\begin{split}
  Var(\nabla Y_t) &= 2 (\gamma_0 - \frac{\gamma_0}{\gamma_0} \gamma_{k}) \\
  &= 2 (\gamma_0 - \rho_k \gamma_0) \\
  &= 2 \gamma_0 (1 - \rho_k) \\
\end{split}
$$

Thus, for $\rho_k < 0.5$ for $k = 1$, then $2 (1 - \rho_k) > 1$, and hence when multiplied by $\gamma_0$, is larger than $Var(Y_t) = \gamma_0$.


\begin{flushright}
  $\blacksquare$
\end{flushright}

\pagebreak

# 4. The data set \texttt{gold} from the \texttt{TSA} library contains the daily price of gold for 252 trading days in 2005.

```{r}
data(gold)
```

## (a) Construct a time series plot of the price of gold $Y_t$. What are the interesting features of this process?

```{r, fig.height=4, fig.width=5, fig.align='center'}
par(cex=1)
plot(gold, ylab="Gold Price", pch=".")
```

The price of gold does not seem to be based on a deterministic trend, as we can see it begins to increase in variance after 150 days.

## (b) Let $W_t = \nabla (\ln Y_t)$, the differences of the logarithms. Construct a time series plot of $W_t$. Does it look stationary?

```{r, fig.height=4, fig.width=5, fig.align='center', warning=FALSE}
plot(diff(log(gold)))
stationary <- adf.test(diff(log(gold)), alternative = "stationary")
```

This looks heteroskedastic, and therefore not stationary, however, the variance is actually quite small, between `r min(diff(log(gold)))` and `r max(diff(log(gold)))`. 

Performing an Augmented Dickey-Fuller test for stationarity, we have a p-value of `r stationary$p.value`, so we reject the null hypothesis. The difference appears to be stationary.


## (c) Use the sample ACF to investigate whether $W_t$ is a white noise process.

```{r, fig.height=4, fig.width=5, fig.align='center'}
acf(diff(log(gold)))
```

The ACF of the log difference appears to follow a white noise process.

## (d) Investigate whether $W_t$ is a normal white noise process.

```{r, fig.height=4, fig.width=5, fig.align='center'}
hist(diff(log(gold)), breaks=100)
qqnorm(diff(log(gold)))
qqline(diff(log(gold)))
gold.test <- shapiro.test(diff(log(gold)))
```

Although there are some outliers at the extremes, running a Shapiro-Wilk test for normality results in a p-value of `r gold.test$p.value` < 0.05, so we can say this is a normal white noise process.

\begin{flushright}
  $\blacksquare$
\end{flushright}

\pagebreak
